{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINGER TAPPING ANALYSIS\n",
    "##### Data collected from patients with neurodegenerative disorders as well as healthy controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "import math\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Flatten, Dropout, MaxPooling1D, Dense\n",
    "from keras.layers import Activation, BatchNormalization, concatenate\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "train = scipy.io.loadmat('TrainData.mat')\n",
    "val = scipy.io.loadmat('ValData.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain = train['X'], train['Y']\n",
    "Xval, Yval = val['X'], val['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arite, lez make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNModel(inputShape, nConvLayers):\n",
    "    \n",
    "    input1 = Input(shape = inputShape)\n",
    "\n",
    "    #convolutions\n",
    "    x = input1\n",
    "    for i in range(0,nConvLayers):\n",
    "        \n",
    "        nFilters = 256 if i>1 else 64*(i+1)\n",
    "        inside = 3 if i>1 else 2\n",
    "        for temp in range(0,inside):\n",
    "            x = Conv1D(filters = nFilters,\n",
    "                  kernel_size = 5,\n",
    "                  padding = 'same',\n",
    "                  strides = 1,\n",
    "                  name = 'Conv1x5{}{}'.format(i,temp))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu',name='ReLu{}{}'.format(i,temp))(x)\n",
    "            \n",
    "        x = MaxPooling1D(2,\n",
    "                      padding = 'same',\n",
    "                      strides = 1,\n",
    "                      name = 'MaxPooling1D{}'.format(i))(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "    \n",
    "    # Fully connected\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Activation('relu', name = 'reLU_dense')(x)\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation('softmax',name = 'Softmax')(x)\n",
    "\n",
    "    m = Model(input1,x)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionModel(inputShape):\n",
    "    \n",
    "    input1 = Input(shape = inputShape)\n",
    "\n",
    "    #conv1\n",
    "    x = Conv1D(filters = 64,\n",
    "              kernel_size = 5,\n",
    "              padding = 'same',\n",
    "              strides = 1,\n",
    "              name = 'Conv1')(input1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu',name='ReLu1')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # inception 2\n",
    "    x3 = Conv1D(filters = 64,\n",
    "              kernel_size = 1,\n",
    "              padding = 'same',\n",
    "              strides = 1)(x)\n",
    "    x3 = Conv1D(filters = 64,\n",
    "               kernel_size = 5,\n",
    "               padding = 'same',\n",
    "               strides = 1,\n",
    "               name = 'Conv1x5')(x3)\n",
    "\n",
    "    x5 = Conv1D(filters = 64,\n",
    "              kernel_size = 1,\n",
    "              padding = 'same',\n",
    "              strides = 1)(x)\n",
    "    x5 = Conv1D(filters = 64,\n",
    "              kernel_size = 7,\n",
    "              padding = 'same',\n",
    "              strides = 1,\n",
    "              name = 'Conv1x7')(x5)\n",
    "\n",
    "    xmax = MaxPooling1D(3,\n",
    "              padding = 'same',\n",
    "              strides = 1,\n",
    "              name = 'MaxPoolIncept')(x)\n",
    "    xmax = Conv1D(filters = 64,\n",
    "              kernel_size = 1,\n",
    "              padding = 'same',\n",
    "              strides = 1)(xmax)\n",
    "\n",
    "    x357 = concatenate([x3,x5,xmax])\n",
    "\n",
    "    #conv 3\n",
    "    x = Conv1D(filters = 256,\n",
    "              kernel_size = 3,\n",
    "              padding = 'same',\n",
    "              strides = 1,\n",
    "              name = 'Conv3')(x357)\n",
    "    \n",
    "    x = Activation('relu',name='ReLu3')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "\n",
    "    # Fully connected\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Activation('relu', name = 'reLU_dense')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation('sigmoid',name = 'Softmax')(x)\n",
    "\n",
    "    m = Model(input1,x)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModelTopology(model,modelName):\n",
    "    model_json = model.to_json()\n",
    "    with open(modelName+'.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    print(\"Saved model to {}.json.\".format(modelName))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defCallbacks(weightFile):\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(weightFile,\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only = True,\n",
    "                                 save_weights_only = True,\n",
    "                                 mode='max')\n",
    "    early = EarlyStopping(monitor='val_acc',\n",
    "                          patience = 10,\n",
    "                          verbose = 1,\n",
    "                          mode='max')\n",
    "    return [checkpoint, early]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModel(model, modelName, Xtrain, Ytrain, Xval, Yval, epochs):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    # make file name\n",
    "    tm = time.gmtime()\n",
    "    weightFile = '{}.{}.{}.{}.{}.{}.h5'.format(modelName,tm[2],tm[1],tm[0],tm[3]+1,tm[4])\n",
    "    \n",
    "    #define callbacks\n",
    "    callbacks = defCallbacks(weightFile)\n",
    "    \n",
    "    # FIT THE MODEL\n",
    "    history = model.fit(x = Xtrain, y = Ytrain,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=4,\n",
    "                        validation_data = (Xval,Yval),\n",
    "                        callbacks = callbacks)\n",
    "    toc = time.time()\n",
    "    print(\"Finished training in {} min ({} h)\".format(round((toc-tic)/60,2),round((toc-tic)/3600,2)))\n",
    "\n",
    "    \n",
    "    # Save the weights\n",
    "    model.save_weights(str(modelName)+'.h5') # ???????\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, modelName, Xval, Yval):\n",
    "    tic = time.time()\n",
    "    predictions = model.predict(Xval)\n",
    "    toc = time.time()\n",
    "    print('Finished prediction in: {} min'.format(round((toc-tic)/60,2)))\n",
    "\n",
    "    print('Evaluating...')\n",
    "    score = model.evaluate(Xval,Yval,verbose=1)\n",
    "    print(score)\n",
    "\n",
    "    #Save that stuff too pls.\n",
    "    tm = time.gmtime()    \n",
    "    predictionFile = 'Predictions-{}.{}.{}.{}.{}.{}.csv'.format(modelName,tm[2],tm[1],tm[0],tm[3]+1,tm[4])\n",
    "\n",
    "    dfPredicted = pd.DataFrame(predictions)\n",
    "    dfPredicted = dfPredicted.idxmax(axis =1)\n",
    "    dfExpected = pd.DataFrame(Yval)\n",
    "    dfExpected = dfExpected.idxmax(axis =1)\n",
    "    df = pd.DataFrame({'Predicted':dfPredicted, 'Expected':dfExpected})\n",
    "    df.to_csv(predictionFile,index = False)\n",
    "    print('Saved predictions to: ', predictionFile)\n",
    "    \n",
    "    bingos = sum(df['Predicted'] ==df['Expected'])\n",
    "    accRly = 100*bingos/df.shape[0]\n",
    "    print('Currently your actual accuracy on Xval is: {}%'.format(round(accRly,2)))\n",
    "    \n",
    "    return accRly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2000, 6)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv1D)                  (None, 2000, 64)     1984        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2000, 64)     256         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ReLu1 (Activation)              (None, 2000, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2000, 64)     0           ReLu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2000, 64)     4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2000, 64)     4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPoolIncept (MaxPooling1D)    (None, 2000, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv1x5 (Conv1D)                (None, 2000, 64)     20544       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv1x7 (Conv1D)                (None, 2000, 64)     28736       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2000, 64)     4160        MaxPoolIncept[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2000, 192)    0           Conv1x5[0][0]                    \n",
      "                                                                 Conv1x7[0][0]                    \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv3 (Conv1D)                  (None, 2000, 256)    147712      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ReLu3 (Activation)              (None, 2000, 256)    0           Conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1000, 256)    0           ReLu3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 256)    0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1000, 256)    1024        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256000)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32768128    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reLU_dense (Activation)         (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           reLU_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            516         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Softmax (Activation)            (None, 4)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,981,380\n",
      "Trainable params: 32,980,740\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n",
      "Saved model to InceptAttempt.json.\n",
      "TRAINING...\n",
      "Train on 2719 samples, validate on 375 samples\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "modelDepths = []\n",
    "accuracies = []\n",
    "\n",
    "for nConvLayers in range(3,4):\n",
    "    model = inceptionModel((Xtrain.shape[1],Xtrain.shape[2]))\n",
    "    \n",
    "    #model = CNNModel((Xtrain.shape[1],Xtrain.shape[2]),nConvLayers)\n",
    "    opt = optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer = opt,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    #modelName = 'CNN_{}_Layers_Deep'.format(nConvLayers)\n",
    "    modelName = 'InceptAttempt'\n",
    "    saveModelTopology(model,modelName)\n",
    "    \n",
    "    print('TRAINING...')\n",
    "    epochs = 200\n",
    "    history = fitModel(model,modelName, Xtrain, Ytrain, Xval, Yval, epochs)\n",
    "    histories.append(history.history)   \n",
    "    modelDepths.append(nConvLayers)\n",
    "        \n",
    "    # check how it went\n",
    "    print(history.history)\n",
    "\n",
    "    # plot Accuracy over Epochs\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Acc','Val Acc'])\n",
    "    plt.title('Accuracy for {} over epochs'.format(modelName))\n",
    "    plt.show()\n",
    "\n",
    "    # plot Loss over Epochs\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss','Val Loss'])\n",
    "    plt.title('Loss for {} over epochs'.format(modelName))\n",
    "    plt.show()\n",
    "    \n",
    "#     acc = evaluateModel(model, modelName, Xval, Yval)\n",
    "#     accuracies.append(acc)\n",
    "    \n",
    "    \n",
    "    with open(\"hist.txt\", \"w\") as f:\n",
    "        for h in histories:\n",
    "            f.write(str(h) +\"\\n\")\n",
    "\n",
    "#     with open(\"hist.txt\", \"r\") as f:\n",
    "#         for line in f:\n",
    "#             histo.append(int(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
